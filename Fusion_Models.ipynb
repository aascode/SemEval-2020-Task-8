{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fusion_Models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PV8ICvcap8X0",
        "colab_type": "text"
      },
      "source": [
        "#Loading and Processing Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlDZHMbGpHkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWOKg5azpVh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Dataset download from kaggle (https://www.kaggle.com/williamscott701/memotion-dataset-7k)\n",
        "#Please download a kaggle.json issued against your kaggle account to run this notebook\n",
        "\n",
        "!pip install -U -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!kaggle datasets download -d williamscott701/memotion-dataset-7k\n",
        "!unzip /content/memotion-dataset-7k.zip\n",
        "!rsync --info=progress2 '/content/drive/My Drive/2000_data.zip' '/content/'\n",
        "!unzip '/content/2000_data.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSZtwQaypVfh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm,tqdm_notebook\n",
        "from sklearn.metrics import f1_score,accuracy_score\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBGrW-wgpVbu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train=pd.read_csv('/content/Final_train.csv')\n",
        "val=pd.read_csv('/content/Final_val.csv')\n",
        "test=pd.read_csv('/content/final_test.csv')\n",
        "print(train.shape)\n",
        "print(val.shape)\n",
        "print(test.shape)\n",
        "\n",
        "# output:\n",
        "# (5943, 8)\n",
        "# (1049, 8)\n",
        "# (1878, 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfoS5LSuHnwv",
        "colab_type": "text"
      },
      "source": [
        "Transforming data labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjTagbcEpVZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting removing 'very' from labels as suggested by the organizers of the competition\n",
        "\n",
        "for i in range(train.shape[0]):\n",
        "  if train.iloc[i,7]=='neutral':\n",
        "    train.iloc[i,7]=0\n",
        "  elif train.iloc[i,7]=='positive' or train.iloc[i,7]=='very_positive':\n",
        "    train.iloc[i,7]=1\n",
        "  else :\n",
        "    train.iloc[i,7]=2    \n",
        "for i in range(val.shape[0]):\n",
        "  if val.iloc[i,7]=='neutral':\n",
        "    val.iloc[i,7]=0\n",
        "  elif val.iloc[i,7]=='positive' or val.iloc[i,7]=='very_positive':\n",
        "    val.iloc[i,7]=1\n",
        "  else :\n",
        "    val.iloc[i,7]=2   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6150BfXwHxeY",
        "colab_type": "text"
      },
      "source": [
        "Dropping unneccessary columns and keeping only text and image file name columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBGVRPlApVXx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train=train.iloc[:,[2,7,0]]\n",
        "data_val=val.iloc[:,[2,7,0]]\n",
        "data_train.columns=[0,1,2]\n",
        "data_val.columns=[0,1,2]\n",
        "data_test=test.loc[:,['corrected_text','Image_URL','Image_name']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFm-t1VpHyh6",
        "colab_type": "text"
      },
      "source": [
        "Regex Transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPCaDqJ8pVVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "def process(data):\n",
        "  for i in tqdm(range(data.shape[0])):\n",
        "    eg=re.sub('[^a-zA-Z]',' ',data.iloc[i,0])\n",
        "    #eg=re.sub('(?!^)([A-Z][a-z]+)', r' \\1', eg).lower()\n",
        "    #eg=re.sub(r'^\"|\"$', '', eg)\n",
        "    eg=\" \".join(eg.lower().split())\n",
        "    #eg=eg.split()\n",
        "    #ps=PorterStemmer()\n",
        "    #eg=[word for word in eg if not word in set(stopwords.words('english'))]\n",
        "    #eg=\" \".join(eg)\n",
        "    \n",
        "    data.iloc[i,0]=eg\n",
        "  return data  \n",
        "\n",
        "\n",
        "data_train=process(data_train.copy())\n",
        "data_val=process(data_val.copy())\n",
        "data_test=process(data_test.copy())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gROKNfwbtnBf",
        "colab_type": "text"
      },
      "source": [
        "#Model Training and Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74DZr4ppGsfh",
        "colab_type": "text"
      },
      "source": [
        "Installing Transformers library to use Roberta Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZ93x4oNpVSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NQXJiosGycr",
        "colab_type": "text"
      },
      "source": [
        "Hand Crafted Label Encoding (external libraries can also be used here for achieving same encoding) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_Em1KGJpVQC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "for i in range(train.shape[0]):\n",
        "  if train.iloc[i,3]=='hilarious':\n",
        "    train.iloc[i,3]=3\n",
        "  if train.iloc[i,3]=='very_funny':\n",
        "    train.iloc[i,3]=2  \n",
        "  if train.iloc[i,3]=='funny':\n",
        "    train.iloc[i,3]=1\n",
        "  if train.iloc[i,3]=='not_funny':\n",
        "    train.iloc[i,3]=0\n",
        "\n",
        "  if train.iloc[i,4]=='very_twisted':\n",
        "    train.iloc[i,4]=3\n",
        "  if train.iloc[i,4]=='twisted_meaning':\n",
        "    train.iloc[i,4]=2  \n",
        "  if train.iloc[i,4]=='general':\n",
        "    train.iloc[i,4]=1\n",
        "  if train.iloc[i,4]=='not_sarcastic':\n",
        "    train.iloc[i,4]=0    \n",
        "\n",
        "  if train.iloc[i,5]=='hateful_offensive':\n",
        "    train.iloc[i,5]=3\n",
        "  if train.iloc[i,5]=='very_offensive':\n",
        "    train.iloc[i,5]=2  \n",
        "  if train.iloc[i,5]=='slight':\n",
        "    train.iloc[i,5]=1\n",
        "  if train.iloc[i,5]=='not_offensive':\n",
        "    train.iloc[i,5]=0    \n",
        "\n",
        "  if train.iloc[i,6]=='motivational':\n",
        "    train.iloc[i,6]=1\n",
        "  if train.iloc[i,6]=='not_motivational':\n",
        "    train.iloc[i,6]=0    \n",
        "\n",
        "for i in range(val.shape[0]):\n",
        "  if val.iloc[i,3]=='hilarious':\n",
        "    val.iloc[i,3]=3\n",
        "  if val.iloc[i,3]=='very_funny':\n",
        "    val.iloc[i,3]=2  \n",
        "  if val.iloc[i,3]=='funny':\n",
        "    val.iloc[i,3]=1\n",
        "  if val.iloc[i,3]=='not_funny':\n",
        "    val.iloc[i,3]=0\n",
        "\n",
        "  if val.iloc[i,4]=='very_twisted':\n",
        "    val.iloc[i,4]=3\n",
        "  if val.iloc[i,4]=='twisted_meaning':\n",
        "    val.iloc[i,4]=2  \n",
        "  if val.iloc[i,4]=='general':\n",
        "    val.iloc[i,4]=1\n",
        "  if val.iloc[i,4]=='not_sarcastic':\n",
        "    val.iloc[i,4]=0    \n",
        "\n",
        "  if val.iloc[i,5]=='hateful_offensive':\n",
        "    val.iloc[i,5]=3\n",
        "  if val.iloc[i,5]=='very_offensive':\n",
        "    val.iloc[i,5]=2  \n",
        "  if val.iloc[i,5]=='slight':\n",
        "    val.iloc[i,5]=1\n",
        "  if val.iloc[i,5]=='not_offensive':\n",
        "    val.iloc[i,5]=0    \n",
        "\n",
        "  if val.iloc[i,6]=='motivational':\n",
        "    val.iloc[i,6]=1\n",
        "  if val.iloc[i,6]=='not_motivational':\n",
        "    val.iloc[i,6]=0    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ch2GeBBrG23a",
        "colab_type": "text"
      },
      "source": [
        "Setting target values for the model depending on the task being solved out of A, B, C (https://competitions.codalab.org/competitions/20629)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJMy-jRcpVN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "cls='offensive' #possible values : humour\tsarcasm\toffensive\tmotivational\toverall_sentiment\n",
        "data_train[1]=train[cls]\n",
        "data_val[1]=val[cls]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ-UiACFG5F2",
        "colab_type": "text"
      },
      "source": [
        "Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPwaK64TpVKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "import imageio\n",
        "import PIL\n",
        "from PIL import ImageFile\n",
        "import cv2\n",
        "from tqdm import tqdm_notebook\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "import tensorflow as tf \n",
        "from tensorflow.keras.layers import Input,Dense,Conv2D,MaxPooling2D,Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3stOSFdG85e",
        "colab_type": "text"
      },
      "source": [
        "Upsampling Data to handle class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhpyCn4TpVIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "UpSample=True\n",
        "\n",
        "if UpSample:\n",
        "  from imblearn.under_sampling import RandomUnderSampler\n",
        "  from imblearn.over_sampling import RandomOverSampler\n",
        "  #=RandomUnderSampler(random_state=42,).fit_resample(X,Y)\n",
        "  #X,Y=RandomUnderSampler(random_state=42).fit_resample(data_train.iloc[:,0][:,np.newaxis],data_train.iloc[:,1])\n",
        "  X,Y=RandomOverSampler(random_state=42).fit_resample(data_train.iloc[:,[0,2]],data_train.iloc[:,1])\n",
        "  data_train=pd.concat((pd.DataFrame(X),pd.DataFrame(Y)),axis=1)\n",
        "  data_train.columns=['text','image','class']\n",
        "  data_val.columns=['text','class','image']\n",
        "  data_test.columns=['text','class','image']\n",
        "  data_train\n",
        "else:\n",
        "  data_train.columns=['text','class','image']\n",
        "  data_val.columns=['text','class','image'] \n",
        "  data_test.columns=['text','class','image']\n",
        "  data_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3r1oVSjtG_vr",
        "colab_type": "text"
      },
      "source": [
        "Setting maximum sequence length for the inputs to RoBERTa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cn4hgYzy5G0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_seq_length=0\n",
        "for i in tqdm(range(data_train.shape[0])):\n",
        "    max_seq_length=max(len(data_train.iloc[i,0].split()),max_seq_length)\n",
        "max_seq_length=max_seq_length+2     \n",
        "print(max_seq_length)\n",
        "\n",
        "# output : \n",
        "# 201"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BJInunOHLPu",
        "colab_type": "text"
      },
      "source": [
        "Textual data processing function to prepare meme overlay text for input to Roberta Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9pOxLc3y5En",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def convert_examples_to_features(sentences, label_list, max_seq_length, tokenizer):\n",
        "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
        "\n",
        "    input_ids, input_masks, segment_ids, labels = [], [], [], []\n",
        "    for index in range(len(sentences)):\n",
        "        sentence = sentences[index] #example.text_a.split(' ')\n",
        "        if sentence=='':\n",
        "          sentence=\" \"\n",
        "        input_id = tokenizer.encode_plus(sentence,max_length=max_seq_length,pad_to_max_length=True)['input_ids']\n",
        "        input_mask = tokenizer.encode_plus(sentence,max_length=max_seq_length,pad_to_max_length=True)['attention_mask']\n",
        "        segment_id = tokenizer.encode_plus(sentence,max_length=max_seq_length,pad_to_max_length=True)['token_type_ids']\n",
        "        label = label_list[index]\n",
        "        input_ids.append(input_id)\n",
        "        input_masks.append(input_mask)\n",
        "        segment_ids.append(segment_id)\n",
        "        labels.append(label)\n",
        "    return (\n",
        "        np.array(input_ids),\n",
        "        np.array(input_masks),\n",
        "        np.array(segment_ids),\n",
        "        np.array(labels)\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9z7tI6_HMV0",
        "colab_type": "text"
      },
      "source": [
        "Processing textual data using above function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLh9nrZ5y5Bf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from transformers import *\n",
        "tokenizer=RobertaTokenizer.from_pretrained('roberta-base')\n",
        "\n",
        "data_train=data_train.reset_index(drop=True)\n",
        "data_val=data_val.reset_index(drop=True)\n",
        "\n",
        "(train_input_ids, train_input_masks, train_segment_ids, train_labels \n",
        ") = convert_examples_to_features(data_train['text'],data_train['class'],max_seq_length,tokenizer)\n",
        "\n",
        "(val_input_ids, val_input_masks, val_segment_ids, val_labels \n",
        ") = convert_examples_to_features(data_val['text'],data_val['class'],max_seq_length,tokenizer)\n",
        "\n",
        "(test_input_ids, test_input_masks, test_segment_ids, test_labels \n",
        ") = convert_examples_to_features(data_test['text'],np.ones(data_test.shape[0]),max_seq_length,tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9aGFytRHQMw",
        "colab_type": "text"
      },
      "source": [
        "Custom Data Loader for keras models used latter in the notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bTMTsq1zWrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def generateTrainingData(dataset, bs, max_seq_length):\n",
        "  \n",
        "  y_batch = []\n",
        "  x_batch_pic=[]\n",
        "  while True:\n",
        "\n",
        "    for i in range(math.ceil(dataset.shape[0]/bs)):\n",
        "\n",
        "        y_batch=train_labels[i*bs:min(i*bs+bs,train_labels.shape[0])]\n",
        "        \n",
        "        for j in range(i*bs,min(i*bs+bs,data_train.shape[0])):\n",
        "          try:\n",
        "            img = PIL.Image.open('/content/memotion_dataset_7k/images/'+str(dataset['image'][j]))\n",
        "          except:\n",
        "            img = PIL.Image.open('/content/drive/My Drive/2000_data/'+str(dataset['image'][j]))  \n",
        "\n",
        "          img=img.resize((256,256))  \n",
        "          try:\n",
        "            img = np.asarray( img, dtype='uint8' )\n",
        "          except SystemError:\n",
        "            img = np.asarray( img.getdata(), dtype='uint8' )\n",
        "\n",
        "          if len(img.shape)<3:\n",
        "            img=img[:,:,np.newaxis]   \n",
        "            \n",
        "          if img.shape[2]<=2:\n",
        "            img=cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "          if img.shape[2]>3:  \n",
        "            img=cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
        "\n",
        "          if len(img.shape)>3 or img.shape[2]!=3:\n",
        "            raise ValueError(str(row['image'])+\" \"+str(img.shape)+\"has a problem\")      \n",
        "\n",
        "      \n",
        "          img=img/255\n",
        "          x_batch_pic.append(img)\n",
        "\n",
        "\n",
        "        yield np.array(x_batch_pic),y_batch\n",
        "\n",
        "        y_batch = []\n",
        "        x_batch_pic=[]\n",
        "          \n",
        "def generatePredictionData(dataset, bs, max_seq_length):\n",
        "  \n",
        "  x_batch = []\n",
        "  #y_batch = []\n",
        "  x_batch_pic=[]\n",
        "  while True:\n",
        "\n",
        "    for i in (range(math.ceil(dataset.shape[0]/bs))):\n",
        "\n",
        "        \n",
        "        for j in range(i*bs,min(i*bs+bs,data_val.shape[0])):\n",
        "          try:\n",
        "            img = PIL.Image.open('/content/memotion_dataset_7k/images/'+str(dataset['image'][j]))\n",
        "          except:\n",
        "            img = PIL.Image.open('/content/drive/My Drive/2000_data/'+str(dataset['image'][j]))  \n",
        "\n",
        "          img=img.resize((256,256))  \n",
        "          try:\n",
        "            img = np.asarray( img, dtype='uint8' )\n",
        "          except SystemError:\n",
        "            img = np.asarray( img.getdata(), dtype='uint8' )\n",
        "\n",
        "          if len(img.shape)<3:\n",
        "            img=img[:,:,np.newaxis]   \n",
        "            \n",
        "          if img.shape[2]<=2:\n",
        "            img=cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "          if img.shape[2]>3:  \n",
        "            img=cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
        "\n",
        "          if len(img.shape)>3 or img.shape[2]!=3:\n",
        "            raise ValueError(str(row['image'])+\" \"+str(img.shape)+\"has a problem\")\n",
        "      \n",
        "          img=img/255\n",
        "          x_batch_pic.append(img)\n",
        "          \n",
        "        \n",
        "\n",
        "        yield np.array(x_batch_pic)#, np.array(y_batch)\n",
        "\n",
        "        x_batch = []\n",
        "        #y_batch = []\n",
        "        x_batch_pic=[]\n",
        "\n",
        "def generateTestPredictionData(dataset, bs, max_seq_length):\n",
        "  \n",
        "  x_batch = []\n",
        "  #y_batch = []\n",
        "  x_batch_pic=[]\n",
        "  while True:\n",
        "\n",
        "    for i in (range(math.ceil(dataset.shape[0]/bs))):\n",
        "\n",
        "        for j in range(i*bs,min(i*bs+bs,data_test.shape[0])):\n",
        "          try:\n",
        "            img = PIL.Image.open('/content/memotion_dataset_7k/images/'+str(dataset['image'][j]))\n",
        "          except:\n",
        "            img = PIL.Image.open('/content/2000_data/'+str(dataset['image'][j]))  \n",
        "\n",
        "          img=img.resize((256,256))  \n",
        "          try:\n",
        "            img = np.asarray( img, dtype='uint8' )\n",
        "          except SystemError:\n",
        "            img = np.asarray( img.getdata(), dtype='uint8' )\n",
        "\n",
        "          if len(img.shape)<3:\n",
        "            img=img[:,:,np.newaxis]   \n",
        "            \n",
        "          if img.shape[2]<=2:\n",
        "            img=cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "          if img.shape[2]>3:  \n",
        "            img=cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
        "\n",
        "          if len(img.shape)>3 or img.shape[2]!=3:\n",
        "            raise ValueError(str(row['image'])+\" \"+str(img.shape)+\"has a problem\")\n",
        "      \n",
        "          img=img/255\n",
        "\n",
        "          x_batch_pic.append(img)\n",
        "\n",
        "        #print(dataset.iloc[i*bs]['text'])\n",
        "\n",
        "        yield np.array(x_batch_pic)#, np.array(y_batch)\n",
        "\n",
        "        x_batch = []\n",
        "        #y_batch = []\n",
        "        x_batch_pic=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "974EAH_6HWC0",
        "colab_type": "text"
      },
      "source": [
        "Defining F1 metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BR8ni2BYzWfn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    y_pred = K.round(y_pred)\n",
        "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
        "    # tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
        "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
        "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
        "\n",
        "    p = tp / (tp + fp + K.epsilon())\n",
        "    r = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "    f1 = 2*p*r / (p+r+K.epsilon())\n",
        "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "    return K.mean(f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PSFa8rX4O2s",
        "colab_type": "text"
      },
      "source": [
        "Early Fusion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvYOom6zWcn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input,Dense,Bidirectional,Conv2D,MaxPooling2D,Flatten,concatenate,GlobalAveragePooling2D,BatchNormalization,Lambda,Add,Multiply\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.metrics import f1_score,accuracy_score\n",
        "\n",
        "token_inputs = tf.keras.layers.Input(shape=(None,), name='word_inputs', dtype=tf.int32)\n",
        "mask_inputs = tf.keras.layers.Input(shape=(None,), name='mask_inputs', dtype=tf.int32)\n",
        "seg_inputs = tf.keras.layers.Input(shape=(None,), name='seg_inputs', dtype=tf.int32)\n",
        "\n",
        "image_inputs=tf.keras.layers.Input(shape=(256,256,3),name=\"meme_images\")\n",
        "\n",
        "\n",
        "inputs=[token_inputs,mask_inputs,seg_inputs,image_inputs]\n",
        "text_inputs=[token_inputs,mask_inputs,seg_inputs]\n",
        "\n",
        "\n",
        "transformer_outputs= TFRobertaModel.from_pretrained('roberta-base')(text_inputs)[0][:,0,:]\n",
        "transformer_outputs=tf.keras.layers.BatchNormalization()(transformer_outputs)\n",
        "\n",
        "image_step=tf.keras.applications.ResNet50(include_top=False, weights='imagenet', input_tensor=None, input_shape=(256,256,3), pooling=False, classes=3,)(image_inputs)\n",
        "image_step=GlobalAveragePooling2D()(image_step)\n",
        "image_step=tf.keras.layers.Dense(768,activation='relu')(image_step)\n",
        "image_step=tf.keras.layers.BatchNormalization()(image_step)\n",
        "\n",
        "\n",
        "\n",
        "concat_output=concatenate([transformer_outputs,image_step],axis=1)\n",
        "# concat_output=tf.keras.layers.LayerNormalization()(concat_output)\n",
        "\n",
        "h=Dense(256,activation='relu')(concat_output)\n",
        "pred=Dense(3,activation='softmax')(h)\n",
        "\n",
        "model=Model(inputs=inputs,outputs=pred)\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "                      optimizer=Adam(lr=2e-5, clipnorm=1.),\n",
        "                      metrics=[f1,'accuracy'])\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBEwtp8Y4Vip",
        "colab_type": "text"
      },
      "source": [
        "Gated MultiModal Unit (GMU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsCVD0Sc4WUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input,Dense,Bidirectional,Conv2D,MaxPooling2D,Flatten,concatenate,GlobalAveragePooling2D,BatchNormalization,Lambda,Add,Multiply\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.metrics import f1_score,accuracy_score\n",
        "\n",
        "token_inputs = tf.keras.layers.Input(shape=(None,), name='word_inputs', dtype=tf.int32)\n",
        "mask_inputs = tf.keras.layers.Input(shape=(None,), name='mask_inputs', dtype=tf.int32)\n",
        "seg_inputs = tf.keras.layers.Input(shape=(None,), name='seg_inputs', dtype=tf.int32)\n",
        "\n",
        "image_inputs=tf.keras.layers.Input(shape=(256,256,3),name=\"meme_images\")\n",
        "\n",
        "\n",
        "inputs=[token_inputs,mask_inputs,seg_inputs,image_inputs]\n",
        "text_inputs=[token_inputs,mask_inputs,seg_inputs]\n",
        "\n",
        "\n",
        "transformer_outputs= TFRobertaModel.from_pretrained('roberta-base')(text_inputs)[0][:,0,:]\n",
        "transformer_outputs=tf.keras.layers.BatchNormalization()(transformer_outputs)\n",
        "\n",
        "image_step=tf.keras.applications.ResNet50(include_top=False, weights='imagenet', input_tensor=None, input_shape=(256,256,3), pooling=False, classes=3,)(image_inputs)\n",
        "image_step=GlobalAveragePooling2D()(image_step)\n",
        "image_step=tf.keras.layers.Dense(768,activation='relu')(image_step)\n",
        "image_step=tf.keras.layers.BatchNormalization()(image_step)\n",
        "\n",
        "\n",
        "# Gated Multimodal Block - Begin\n",
        "hv=Dense(768,activation='tanh')(image_step)\n",
        "ht=Dense(768,activation='tanh')(transformer_outputs)\n",
        "z=Dense(768,activation='sigmoid')(concat_output)\n",
        "h=Add()([Multiply()([z,hv]),Multiply()([Lambda(lambda x: 1. - x)(z),ht])])\n",
        "# Gated Multimodal Block - End\n",
        "\n",
        "\n",
        "h=Dense(256,activation='relu')(h)\n",
        "pred=Dense(3,activation='softmax')(h)\n",
        "\n",
        "model=Model(inputs=inputs,outputs=pred)\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "                      optimizer=Adam(lr=2e-5, clipnorm=1.),\n",
        "                      metrics=[f1,'accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sciTsGvHZg4",
        "colab_type": "text"
      },
      "source": [
        "Keras Callbacks to simplify model saving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Maue8pd34tKR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Saver(tf.keras.callbacks.Callback):\n",
        "  def on_train_begin(self,logs={}):\n",
        "    self.score=0\n",
        "    self.epoch_number=0\n",
        "  def on_epoch_end(self,logs={},*args):\n",
        "    test_gen=generatePredictionData(data_val,32,max_seq_length)\n",
        "    predict=np.argmax(self.model.predict_generator(test_gen, steps=data_val.shape[0]//32+1,max_queue_size=10,verbose=1), axis=1)\n",
        "    print(f1_score(data_val['class'].astype('int')[:,np.newaxis],predict[:,np.newaxis],average='macro'))\n",
        "    #if res>self.score:\n",
        "    #    self.score=res\n",
        "    self.model.save_weights('/content/drive/My Drive/model_save_memo/imageC-2-{}.h5'.format(self.epoch_number))\n",
        "    self.epoch_number=self.epoch_number+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDtCWJw5Hbt4",
        "colab_type": "text"
      },
      "source": [
        "Begin Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBkO9t5h4tIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen = generateTrainingData(data_train,32,max_seq_length)\n",
        "model.fit_generator(gen, steps_per_epoch=data_train.shape[0]//32+1,epochs=10, max_queue_size=10, workers=1,shuffle=False,callbacks=[Saver()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7w-vAgVHcjt",
        "colab_type": "text"
      },
      "source": [
        "Test Validation Score "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vC-RWfCO4sdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_gen=generatePredictionData(data_val,32,max_seq_length)\n",
        "predict=model.predict_generator(test_gen, steps=data_val.shape[0]//32+1,max_queue_size=0,verbose=1)\n",
        "print(f1_score(data_val['class'].astype('int')[:,np.newaxis],np.argmax(predict,axis=1),average='macro'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLvl8Um-HgTs",
        "colab_type": "text"
      },
      "source": [
        "Final test predictions for submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqtNbItNATzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_gen=generateTestPredictionData(data_test,32,max_seq_length)\n",
        "predict=model.predict_generator(test_gen, steps=data_test.shape[0]//32+1,max_queue_size=0,verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf81mVKoHhI9",
        "colab_type": "text"
      },
      "source": [
        "Making submission file based on the task (A,B,C) being solved "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MCURMRSAkkg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('answer.txt',\"w\") as f:\n",
        "  for i in range(len(predict)):\n",
        "    #if predict[i]==2:\n",
        "    #  f.write(str(-1))\n",
        "    #else:\n",
        "    #  f.write(str(predict[i]))\n",
        "    f.write(\"{}_9999_9999\".format(predict[i]))\n",
        "    f.write(\"\\n\")    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}