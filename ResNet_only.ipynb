{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet_only.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PV8ICvcap8X0",
        "colab_type": "text"
      },
      "source": [
        "#Loading and Processing Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlDZHMbGpHkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWOKg5azpVh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Dataset download from kaggle (https://www.kaggle.com/williamscott701/memotion-dataset-7k)\n",
        "#Please download a kaggle.json issued against your kaggle account to run this notebook\n",
        "\n",
        "!pip install -U -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!kaggle datasets download -d williamscott701/memotion-dataset-7k\n",
        "!unzip /content/memotion-dataset-7k.zip\n",
        "!rsync --info=progress2 '/content/drive/My Drive/2000_data.zip' '/content/'\n",
        "!unzip '/content/2000_data.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSZtwQaypVfh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm,tqdm_notebook\n",
        "from sklearn.metrics import f1_score,accuracy_score\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBGrW-wgpVbu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train=pd.read_csv('/content/Final_train.csv')\n",
        "val=pd.read_csv('/content/Final_val.csv')\n",
        "test=pd.read_csv('/content/final_test.csv')\n",
        "print(train.shape)\n",
        "print(val.shape)\n",
        "print(test.shape)\n",
        "\n",
        "# output:\n",
        "# (5943, 8)\n",
        "# (1049, 8)\n",
        "# (1878, 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfoS5LSuHnwv",
        "colab_type": "text"
      },
      "source": [
        "Transforming data labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjTagbcEpVZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting removing 'very' from labels as suggested by the organizers of the competition\n",
        "\n",
        "for i in range(train.shape[0]):\n",
        "  if train.iloc[i,7]=='neutral':\n",
        "    train.iloc[i,7]=0\n",
        "  elif train.iloc[i,7]=='positive' or train.iloc[i,7]=='very_positive':\n",
        "    train.iloc[i,7]=1\n",
        "  else :\n",
        "    train.iloc[i,7]=2    \n",
        "for i in range(val.shape[0]):\n",
        "  if val.iloc[i,7]=='neutral':\n",
        "    val.iloc[i,7]=0\n",
        "  elif val.iloc[i,7]=='positive' or val.iloc[i,7]=='very_positive':\n",
        "    val.iloc[i,7]=1\n",
        "  else :\n",
        "    val.iloc[i,7]=2   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6150BfXwHxeY",
        "colab_type": "text"
      },
      "source": [
        "Dropping unneccessary columns and keeping only text and image file name columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBGVRPlApVXx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train=train.iloc[:,[2,7,0]]\n",
        "data_val=val.iloc[:,[2,7,0]]\n",
        "data_train.columns=[0,1,2]\n",
        "data_val.columns=[0,1,2]\n",
        "data_test=test.loc[:,['corrected_text','Image_URL','Image_name']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFm-t1VpHyh6",
        "colab_type": "text"
      },
      "source": [
        "Regex Transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPCaDqJ8pVVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "def process(data):\n",
        "  for i in tqdm(range(data.shape[0])):\n",
        "    eg=re.sub('[^a-zA-Z]',' ',data.iloc[i,0])\n",
        "    #eg=re.sub('(?!^)([A-Z][a-z]+)', r' \\1', eg).lower()\n",
        "    #eg=re.sub(r'^\"|\"$', '', eg)\n",
        "    eg=\" \".join(eg.lower().split())\n",
        "    #eg=eg.split()\n",
        "    #ps=PorterStemmer()\n",
        "    #eg=[word for word in eg if not word in set(stopwords.words('english'))]\n",
        "    #eg=\" \".join(eg)\n",
        "    \n",
        "    data.iloc[i,0]=eg\n",
        "  return data  \n",
        "\n",
        "\n",
        "data_train=process(data_train.copy())\n",
        "data_val=process(data_val.copy())\n",
        "data_test=process(data_test.copy())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49g5_TP5nXKt",
        "colab_type": "text"
      },
      "source": [
        "# Model Training and Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igUalvb1nkmO",
        "colab_type": "text"
      },
      "source": [
        "Hand Crafted Label Encoding (external libraries can also be used here for achieving same encoding) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuiHZhW7nZRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "for i in range(train.shape[0]):\n",
        "  if train.iloc[i,3]=='hilarious':\n",
        "    train.iloc[i,3]=3\n",
        "  if train.iloc[i,3]=='very_funny':\n",
        "    train.iloc[i,3]=2  \n",
        "  if train.iloc[i,3]=='funny':\n",
        "    train.iloc[i,3]=1\n",
        "  if train.iloc[i,3]=='not_funny':\n",
        "    train.iloc[i,3]=0\n",
        "\n",
        "  if train.iloc[i,4]=='very_twisted':\n",
        "    train.iloc[i,4]=3\n",
        "  if train.iloc[i,4]=='twisted_meaning':\n",
        "    train.iloc[i,4]=2  \n",
        "  if train.iloc[i,4]=='general':\n",
        "    train.iloc[i,4]=1\n",
        "  if train.iloc[i,4]=='not_sarcastic':\n",
        "    train.iloc[i,4]=0    \n",
        "\n",
        "  if train.iloc[i,5]=='hateful_offensive':\n",
        "    train.iloc[i,5]=3\n",
        "  if train.iloc[i,5]=='very_offensive':\n",
        "    train.iloc[i,5]=2  \n",
        "  if train.iloc[i,5]=='slight':\n",
        "    train.iloc[i,5]=1\n",
        "  if train.iloc[i,5]=='not_offensive':\n",
        "    train.iloc[i,5]=0    \n",
        "\n",
        "  if train.iloc[i,6]=='motivational':\n",
        "    train.iloc[i,6]=1\n",
        "  if train.iloc[i,6]=='not_motivational':\n",
        "    train.iloc[i,6]=0    \n",
        "\n",
        "for i in range(val.shape[0]):\n",
        "  if val.iloc[i,3]=='hilarious':\n",
        "    val.iloc[i,3]=3\n",
        "  if val.iloc[i,3]=='very_funny':\n",
        "    val.iloc[i,3]=2  \n",
        "  if val.iloc[i,3]=='funny':\n",
        "    val.iloc[i,3]=1\n",
        "  if val.iloc[i,3]=='not_funny':\n",
        "    val.iloc[i,3]=0\n",
        "\n",
        "  if val.iloc[i,4]=='very_twisted':\n",
        "    val.iloc[i,4]=3\n",
        "  if val.iloc[i,4]=='twisted_meaning':\n",
        "    val.iloc[i,4]=2  \n",
        "  if val.iloc[i,4]=='general':\n",
        "    val.iloc[i,4]=1\n",
        "  if val.iloc[i,4]=='not_sarcastic':\n",
        "    val.iloc[i,4]=0    \n",
        "\n",
        "  if val.iloc[i,5]=='hateful_offensive':\n",
        "    val.iloc[i,5]=3\n",
        "  if val.iloc[i,5]=='very_offensive':\n",
        "    val.iloc[i,5]=2  \n",
        "  if val.iloc[i,5]=='slight':\n",
        "    val.iloc[i,5]=1\n",
        "  if val.iloc[i,5]=='not_offensive':\n",
        "    val.iloc[i,5]=0    \n",
        "\n",
        "  if val.iloc[i,6]=='motivational':\n",
        "    val.iloc[i,6]=1\n",
        "  if val.iloc[i,6]=='not_motivational':\n",
        "    val.iloc[i,6]=0    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcYnvHSRnyyz",
        "colab_type": "text"
      },
      "source": [
        "Setting target values for the model depending on the task being solved out of A, B, C (https://competitions.codalab.org/competitions/20629)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DFLz0aynq-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cls='offensive' #possible values : humour\tsarcasm\toffensive\tmotivational\toverall_sentiment\n",
        "data_train[1]=train[cls]\n",
        "data_val[1]=val[cls]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNOP4Uben7vq",
        "colab_type": "text"
      },
      "source": [
        "Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgGBUn8En3LO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "import imageio\n",
        "import PIL\n",
        "from PIL import ImageFile\n",
        "import cv2\n",
        "from tqdm import tqdm_notebook\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "\n",
        "import tensorflow as tf \n",
        "from tensorflow.keras.layers import Input,Dense,Conv2D,MaxPooling2D,Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxPaU7Won_4G",
        "colab_type": "text"
      },
      "source": [
        "Upsampling Data to handle class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhofsXjqoAQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "UpSample=False\n",
        "\n",
        "if UpSample:\n",
        "  from imblearn.under_sampling import RandomUnderSampler\n",
        "  from imblearn.over_sampling import RandomOverSampler\n",
        "  #=RandomUnderSampler(random_state=42,).fit_resample(X,Y)\n",
        "  #X,Y=RandomUnderSampler(random_state=42).fit_resample(data_train.iloc[:,0][:,np.newaxis],data_train.iloc[:,1])\n",
        "  X,Y=RandomOverSampler(random_state=42).fit_resample(data_train.iloc[:,[0,2]],data_train.iloc[:,1])\n",
        "  data_train=pd.concat((pd.DataFrame(X),pd.DataFrame(Y)),axis=1)\n",
        "  data_train.columns=['text','image','class']\n",
        "  data_val.columns=['text','class','image']\n",
        "  data_test.columns=['text','class','image']\n",
        "  data_train\n",
        "else:\n",
        "  data_train.columns=['text','class','image']\n",
        "  data_val.columns=['text','class','image'] \n",
        "  data_test.columns=['text','class','image']\n",
        "  data_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C15fVt1oGaR",
        "colab_type": "text"
      },
      "source": [
        "Custom Data Loader for keras models used later in the notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOK_KRt6oNE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "import imageio\n",
        "import PIL\n",
        "from PIL import ImageFile\n",
        "import cv2\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "def generateTrainingData(dataset, bs, max_seq_length):\n",
        "  \n",
        "  y_batch = []\n",
        "  x_batch_pic=[]\n",
        "  while True:\n",
        "\n",
        "    for i in range(math.ceil(dataset.shape[0]/bs)):\n",
        "\n",
        "        y_batch=train_labels[i*bs:min(i*bs+bs,train_labels.shape[0])]\n",
        "        \n",
        "        for j in range(i*bs,min(i*bs+bs,data_train.shape[0])):\n",
        "          try:\n",
        "            img = PIL.Image.open('/content/memotion_dataset_7k/images/'+str(dataset['image'][j]))\n",
        "          except:\n",
        "            img = PIL.Image.open('/content/drive/My Drive/2000_data/'+str(dataset['image'][j]))  \n",
        "\n",
        "          img=img.resize((256,256))  \n",
        "          try:\n",
        "            img = np.asarray( img, dtype='uint8' )\n",
        "          except SystemError:\n",
        "            img = np.asarray( img.getdata(), dtype='uint8' )\n",
        "\n",
        "          if len(img.shape)<3:\n",
        "            img=img[:,:,np.newaxis]   \n",
        "            \n",
        "          if img.shape[2]<=2:\n",
        "            img=cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "          if img.shape[2]>3:  \n",
        "            img=cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
        "\n",
        "          if len(img.shape)>3 or img.shape[2]!=3:\n",
        "            raise ValueError(str(row['image'])+\" \"+str(img.shape)+\"has a problem\")      \n",
        "\n",
        "      \n",
        "          img=img/255\n",
        "          x_batch_pic.append(img)\n",
        "\n",
        "\n",
        "        yield np.array(x_batch_pic),y_batch\n",
        "\n",
        "        y_batch = []\n",
        "        x_batch_pic=[]\n",
        "          \n",
        "def generatePredictionData(dataset, bs, max_seq_length):\n",
        "  \n",
        "  x_batch = []\n",
        "  #y_batch = []\n",
        "  x_batch_pic=[]\n",
        "  while True:\n",
        "\n",
        "    for i in (range(math.ceil(dataset.shape[0]/bs))):\n",
        "\n",
        "        \n",
        "        for j in range(i*bs,min(i*bs+bs,data_val.shape[0])):\n",
        "          try:\n",
        "            img = PIL.Image.open('/content/memotion_dataset_7k/images/'+str(dataset['image'][j]))\n",
        "          except:\n",
        "            img = PIL.Image.open('/content/drive/My Drive/2000_data/'+str(dataset['image'][j]))  \n",
        "\n",
        "          img=img.resize((256,256))  \n",
        "          try:\n",
        "            img = np.asarray( img, dtype='uint8' )\n",
        "          except SystemError:\n",
        "            img = np.asarray( img.getdata(), dtype='uint8' )\n",
        "\n",
        "          if len(img.shape)<3:\n",
        "            img=img[:,:,np.newaxis]   \n",
        "            \n",
        "          if img.shape[2]<=2:\n",
        "            img=cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "          if img.shape[2]>3:  \n",
        "            img=cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
        "\n",
        "          if len(img.shape)>3 or img.shape[2]!=3:\n",
        "            raise ValueError(str(row['image'])+\" \"+str(img.shape)+\"has a problem\")\n",
        "      \n",
        "          img=img/255\n",
        "          x_batch_pic.append(img)\n",
        "          \n",
        "        \n",
        "\n",
        "        yield np.array(x_batch_pic)#, np.array(y_batch)\n",
        "\n",
        "        x_batch = []\n",
        "        #y_batch = []\n",
        "        x_batch_pic=[]\n",
        "\n",
        "def generateTestPredictionData(dataset, bs, max_seq_length):\n",
        "  \n",
        "  x_batch = []\n",
        "  #y_batch = []\n",
        "  x_batch_pic=[]\n",
        "  while True:\n",
        "\n",
        "    for i in (range(math.ceil(dataset.shape[0]/bs))):\n",
        "\n",
        "        for j in range(i*bs,min(i*bs+bs,data_test.shape[0])):\n",
        "          try:\n",
        "            img = PIL.Image.open('/content/memotion_dataset_7k/images/'+str(dataset['image'][j]))\n",
        "          except:\n",
        "            img = PIL.Image.open('/content/2000_data/'+str(dataset['image'][j]))  \n",
        "\n",
        "          img=img.resize((256,256))  \n",
        "          try:\n",
        "            img = np.asarray( img, dtype='uint8' )\n",
        "          except SystemError:\n",
        "            img = np.asarray( img.getdata(), dtype='uint8' )\n",
        "\n",
        "          if len(img.shape)<3:\n",
        "            img=img[:,:,np.newaxis]   \n",
        "            \n",
        "          if img.shape[2]<=2:\n",
        "            img=cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "          if img.shape[2]>3:  \n",
        "            img=cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
        "\n",
        "          if len(img.shape)>3 or img.shape[2]!=3:\n",
        "            raise ValueError(str(row['image'])+\" \"+str(img.shape)+\"has a problem\")\n",
        "      \n",
        "          img=img/255\n",
        "\n",
        "          x_batch_pic.append(img)\n",
        "\n",
        "        #print(dataset.iloc[i*bs]['text'])\n",
        "\n",
        "        yield np.array(x_batch_pic)#, np.array(y_batch)\n",
        "\n",
        "        x_batch = []\n",
        "        #y_batch = []\n",
        "        x_batch_pic=[]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgzcSQBpoZqx",
        "colab_type": "text"
      },
      "source": [
        "Defining F1 metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-PUEwc8oTkW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    y_pred = K.round(y_pred)\n",
        "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
        "    # tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
        "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
        "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
        "\n",
        "    p = tp / (tp + fp + K.epsilon())\n",
        "    r = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "    f1 = 2*p*r / (p+r+K.epsilon())\n",
        "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "    return K.mean(f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83dIMaDEpMlb",
        "colab_type": "text"
      },
      "source": [
        "Building Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VO38pFOfobpl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input,Dense,Bidirectional,Conv2D,MaxPooling2D,Flatten,concatenate,GlobalAveragePooling2D,BatchNormalization,Lambda,Add,Multiply\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.metrics import f1_score,accuracy_score\n",
        "\n",
        "\n",
        "image_inputs=tf.keras.layers.Input(shape=(256,256,3),name=\"meme_images\")\n",
        "\n",
        "image_step=tf.keras.applications.ResNet50(include_top=False, weights='imagenet', input_tensor=None, input_shape=(256,256,3), pooling=False, classes=3)(image_inputs)\n",
        "image_step=GlobalAveragePooling2D()(image_step)\n",
        "image_step=tf.keras.layers.Dense(768,activation='relu')(image_step)\n",
        "image_step=tf.keras.layers.BatchNormalization()(image_step)\n",
        "\n",
        "h=Dense(256,activation='relu')(image_step)\n",
        "pred=Dense(4,activation='softmax')(h)\n",
        "\n",
        "model=Model(inputs=image_inputs,outputs=pred)\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "                      optimizer=Adam(lr=2e-5, clipnorm=1.),\n",
        "                      metrics=[f1,'accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Model: \"model\"\n",
        "# _________________________________________________________________\n",
        "# Layer (type)                 Output Shape              Param #   \n",
        "# =================================================================\n",
        "# meme_images (InputLayer)     [(None, 256, 256, 3)]     0         \n",
        "# _________________________________________________________________\n",
        "# resnet50 (Model)             (None, 8, 8, 2048)        23587712  \n",
        "# _________________________________________________________________\n",
        "# global_average_pooling2d (Gl (None, 2048)              0         \n",
        "# _________________________________________________________________\n",
        "# dense (Dense)                (None, 768)               1573632   \n",
        "# _________________________________________________________________\n",
        "# batch_normalization (BatchNo (None, 768)               3072      \n",
        "# _________________________________________________________________\n",
        "# dense_1 (Dense)              (None, 256)               196864    \n",
        "# _________________________________________________________________\n",
        "# dense_2 (Dense)              (None, 4)                 1028      \n",
        "# =================================================================\n",
        "# Total params: 25,362,308\n",
        "# Trainable params: 25,307,652\n",
        "# Non-trainable params: 54,656\n",
        "# _________________________________________________________________"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4z_-R6TNpTTZ",
        "colab_type": "text"
      },
      "source": [
        "Keras Callbacks to simplify model saving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vr8Ws4bYohSl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Saver(tf.keras.callbacks.Callback):\n",
        "  def on_train_begin(self,logs={}):\n",
        "    self.score=0\n",
        "    self.epoch_number=0\n",
        "  def on_epoch_end(self,logs={},*args):\n",
        "    test_gen=generatePredictionData(data_val,32,max_seq_length)\n",
        "    predict=np.argmax(self.model.predict_generator(test_gen, steps=data_val.shape[0]//32+1,max_queue_size=10,verbose=1), axis=1)\n",
        "    print(f1_score(data_val['class'].astype('int')[:,np.newaxis],predict[:,np.newaxis],average='macro'))\n",
        "    #if res>self.score:\n",
        "    #    self.score=res\n",
        "    self.model.save_weights('/content/drive/My Drive/model_save_memo/imageC-2-{}.h5'.format(self.epoch_number))\n",
        "    self.epoch_number=self.epoch_number+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_d_owX0Iopu2",
        "colab_type": "text"
      },
      "source": [
        "Begin Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8wh6B2OorQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen = generateTrainingData(data_train,32,max_seq_length)\n",
        "model.fit_generator(gen, steps_per_epoch=data_train.shape[0]//32+1,epochs=10, max_queue_size=10, workers=1,shuffle=False,callbacks=[Saver()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_7fL2expZvR",
        "colab_type": "text"
      },
      "source": [
        "Test Validation Score "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSpm7mjwow_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_gen=generatePredictionData(data_val,32,max_seq_length)\n",
        "predict=model.predict_generator(test_gen, steps=data_val.shape[0]//32+1,max_queue_size=0,verbose=1)\n",
        "print(f1_score(data_val['class'].astype('int')[:,np.newaxis],np.argmax(predict,axis=1),average='macro'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJs1mJS2pdFG",
        "colab_type": "text"
      },
      "source": [
        "Final test predictions for submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEiR1gSiow8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_gen=generateTestPredictionData(data_test,32,max_seq_length)\n",
        "predict=model.predict_generator(test_gen, steps=data_test.shape[0]//32+1,max_queue_size=0,verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUgtzmY-phJM",
        "colab_type": "text"
      },
      "source": [
        "Making submission file based on the task (A,B,C) being solved "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO72DFTApjJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('answer.txt',\"w\") as f:\n",
        "  for i in range(len(predict)):\n",
        "    #if predict[i]==2:\n",
        "    #  f.write(str(-1))\n",
        "    #else:\n",
        "    #  f.write(str(predict[i]))\n",
        "    f.write(\"{}_9999_9999\".format(predict[i]))\n",
        "    f.write(\"\\n\")    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}