{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RoBERTa_only.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbItPWjEbLwQ",
        "colab_type": "text"
      },
      "source": [
        "#Loading and Processing Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDnRr_oKa5in",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gb4SIDo4bS0q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dataset download from kaggle (https://www.kaggle.com/williamscott701/memotion-dataset-7k)\n",
        "#Please download a kaggle.json issued against your kaggle account to run this notebook\n",
        "\n",
        "!pip install -U -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!kaggle datasets download -d williamscott701/memotion-dataset-7k\n",
        "!unzip /content/memotion-dataset-7k.zip\n",
        "!rsync --info=progress2 '/content/drive/My Drive/2000_data.zip' '/content/'\n",
        "!unzip '/content/2000_data.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZCfG2TCbSyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm,tqdm_notebook\n",
        "from sklearn.metrics import f1_score,accuracy_score\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mt61yeEWbSvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train=pd.read_csv('/content/Final_train.csv')\n",
        "val=pd.read_csv('/content/Final_val.csv')\n",
        "test=pd.read_csv('/content/final_test.csv')\n",
        "print(train.shape)\n",
        "print(val.shape)\n",
        "print(test.shape)\n",
        "\n",
        "# output:\n",
        "# (5943, 8)\n",
        "# (1049, 8)\n",
        "# (1878, 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_CLXsqUbdCN",
        "colab_type": "text"
      },
      "source": [
        "Transforming data labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb3SuqBNbSs1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting removing 'very' from labels as suggested by the organizers of the competition\n",
        "\n",
        "for i in range(train.shape[0]):\n",
        "  if train.iloc[i,7]=='neutral':\n",
        "    train.iloc[i,7]=0\n",
        "  elif train.iloc[i,7]=='positive' or train.iloc[i,7]=='very_positive':\n",
        "    train.iloc[i,7]=1\n",
        "  else :\n",
        "    train.iloc[i,7]=2    \n",
        "for i in range(val.shape[0]):\n",
        "  if val.iloc[i,7]=='neutral':\n",
        "    val.iloc[i,7]=0\n",
        "  elif val.iloc[i,7]=='positive' or val.iloc[i,7]=='very_positive':\n",
        "    val.iloc[i,7]=1\n",
        "  else :\n",
        "    val.iloc[i,7]=2   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYceB3QobeEm",
        "colab_type": "text"
      },
      "source": [
        "Dropping unneccessary columns and keeping only text and image file name columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOYTtgk5bSqv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train=train.iloc[:,[2,7,0]]\n",
        "data_val=val.iloc[:,[2,7,0]]\n",
        "data_train.columns=[0,1,2]\n",
        "data_val.columns=[0,1,2]\n",
        "data_test=test.loc[:,['corrected_text','Image_URL','Image_name']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab3Q2Dcob17V",
        "colab_type": "text"
      },
      "source": [
        "Regex Transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIErqGdzbSon",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "def process(data):\n",
        "  for i in tqdm(range(data.shape[0])):\n",
        "    eg=re.sub('[^a-zA-Z]',' ',data.iloc[i,0])\n",
        "    #eg=re.sub('(?!^)([A-Z][a-z]+)', r' \\1', eg).lower()\n",
        "    #eg=re.sub(r'^\"|\"$', '', eg)\n",
        "    eg=\" \".join(eg.lower().split())\n",
        "    #eg=eg.split()\n",
        "    #ps=PorterStemmer()\n",
        "    #eg=[word for word in eg if not word in set(stopwords.words('english'))]\n",
        "    #eg=\" \".join(eg)\n",
        "    \n",
        "    data.iloc[i,0]=eg\n",
        "  return data  \n",
        "\n",
        "\n",
        "data_train=process(data_train.copy())\n",
        "data_val=process(data_val.copy())\n",
        "data_test=process(data_test.copy())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ib4SGzHb8yq",
        "colab_type": "text"
      },
      "source": [
        "# Model Training and Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcRMN3uvcBXA",
        "colab_type": "text"
      },
      "source": [
        "Installing Transformers library to use Roberta Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAJD0J2Lb5_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlaB0esoju0E",
        "colab_type": "text"
      },
      "source": [
        "Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LmeG7FZjzAB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import h5py\n",
        "import pprint\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "import os \n",
        "import re\n",
        "from tqdm import tqdm_notebook,tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "from transformers import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AT-_j3f9cVfH",
        "colab_type": "text"
      },
      "source": [
        "Hand Crafted Label Encoding (external libraries can also be used here for achieving same encoding) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyWC1doQbSmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "for i in range(train.shape[0]):\n",
        "  if train.iloc[i,3]=='hilarious':\n",
        "    train.iloc[i,3]=3\n",
        "  if train.iloc[i,3]=='very_funny':\n",
        "    train.iloc[i,3]=2  \n",
        "  if train.iloc[i,3]=='funny':\n",
        "    train.iloc[i,3]=1\n",
        "  if train.iloc[i,3]=='not_funny':\n",
        "    train.iloc[i,3]=0\n",
        "\n",
        "  if train.iloc[i,4]=='very_twisted':\n",
        "    train.iloc[i,4]=3\n",
        "  if train.iloc[i,4]=='twisted_meaning':\n",
        "    train.iloc[i,4]=2  \n",
        "  if train.iloc[i,4]=='general':\n",
        "    train.iloc[i,4]=1\n",
        "  if train.iloc[i,4]=='not_sarcastic':\n",
        "    train.iloc[i,4]=0    \n",
        "\n",
        "  if train.iloc[i,5]=='hateful_offensive':\n",
        "    train.iloc[i,5]=3\n",
        "  if train.iloc[i,5]=='very_offensive':\n",
        "    train.iloc[i,5]=2  \n",
        "  if train.iloc[i,5]=='slight':\n",
        "    train.iloc[i,5]=1\n",
        "  if train.iloc[i,5]=='not_offensive':\n",
        "    train.iloc[i,5]=0    \n",
        "\n",
        "  if train.iloc[i,6]=='motivational':\n",
        "    train.iloc[i,6]=1\n",
        "  if train.iloc[i,6]=='not_motivational':\n",
        "    train.iloc[i,6]=0    \n",
        "\n",
        "for i in range(val.shape[0]):\n",
        "  if val.iloc[i,3]=='hilarious':\n",
        "    val.iloc[i,3]=3\n",
        "  if val.iloc[i,3]=='very_funny':\n",
        "    val.iloc[i,3]=2  \n",
        "  if val.iloc[i,3]=='funny':\n",
        "    val.iloc[i,3]=1\n",
        "  if val.iloc[i,3]=='not_funny':\n",
        "    val.iloc[i,3]=0\n",
        "\n",
        "  if val.iloc[i,4]=='very_twisted':\n",
        "    val.iloc[i,4]=3\n",
        "  if val.iloc[i,4]=='twisted_meaning':\n",
        "    val.iloc[i,4]=2  \n",
        "  if val.iloc[i,4]=='general':\n",
        "    val.iloc[i,4]=1\n",
        "  if val.iloc[i,4]=='not_sarcastic':\n",
        "    val.iloc[i,4]=0    \n",
        "\n",
        "  if val.iloc[i,5]=='hateful_offensive':\n",
        "    val.iloc[i,5]=3\n",
        "  if val.iloc[i,5]=='very_offensive':\n",
        "    val.iloc[i,5]=2  \n",
        "  if val.iloc[i,5]=='slight':\n",
        "    val.iloc[i,5]=1\n",
        "  if val.iloc[i,5]=='not_offensive':\n",
        "    val.iloc[i,5]=0    \n",
        "\n",
        "  if val.iloc[i,6]=='motivational':\n",
        "    val.iloc[i,6]=1\n",
        "  if val.iloc[i,6]=='not_motivational':\n",
        "    val.iloc[i,6]=0    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRJ5BIAKjlPx",
        "colab_type": "text"
      },
      "source": [
        "Setting target values for the model depending on the task being solved out of A, B, C (https://competitions.codalab.org/competitions/20629)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myGGyrXzbSkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cls='offensive' #possible values : humour\tsarcasm\toffensive\tmotivational\toverall_sentiment\n",
        "data_train[1]=train[cls]\n",
        "data_val[1]=val[cls]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kcjnm0JojnS6",
        "colab_type": "text"
      },
      "source": [
        "Upsampling Data to handle class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSdxtOE7j27c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "UpSample=True\n",
        "\n",
        "if UpSample:\n",
        "  from imblearn.under_sampling import RandomUnderSampler\n",
        "  from imblearn.over_sampling import RandomOverSampler\n",
        "  #=RandomUnderSampler(random_state=42,).fit_resample(X,Y)\n",
        "  #X,Y=RandomUnderSampler(random_state=42).fit_resample(data_train.iloc[:,0][:,np.newaxis],data_train.iloc[:,1])\n",
        "  X,Y=RandomOverSampler(random_state=42).fit_resample(data_train.iloc[:,[0,2]],data_train.iloc[:,1])\n",
        "  data_train=pd.concat((pd.DataFrame(X),pd.DataFrame(Y)),axis=1)\n",
        "  data_train.columns=['text','image','class']\n",
        "  data_val.columns=['text','class','image']\n",
        "  data_test.columns=['text','waste','image']\n",
        "  data_train\n",
        "\n",
        "else:\n",
        "  data_train.columns=['text','class','image']\n",
        "  data_val.columns=['text','class','image'] \n",
        "  data_test.columns=['text','waste','image']\n",
        "  data_train  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmwIWImrj-DK",
        "colab_type": "text"
      },
      "source": [
        "Setting maximum sequence length for the inputs to RoBERTa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eHXS4p6j6yH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_seq_length=0\n",
        "for i in tqdm(range(data_train.shape[0])):\n",
        "    max_seq_length=max(len(data_train.iloc[i,0].split()),max_seq_length)\n",
        "max_seq_length=max_seq_length+2     \n",
        "print(max_seq_length)\n",
        "\n",
        "# output : \n",
        "# 201"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxQc60tekJfC",
        "colab_type": "text"
      },
      "source": [
        "Textual data processing function to prepare meme overlay text for input to Roberta Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL8A4FEYkGKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_examples_to_features(sentences, label_list, max_seq_length, tokenizer):\n",
        "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
        "\n",
        "    input_ids, input_masks, segment_ids, labels = [], [], [], []\n",
        "    for index in tqdm_notebook(range(len(sentences)),desc=\"Converting examples to features\"):\n",
        "        sentence = sentences[index] #example.text_a.split(' ')\n",
        "        if sentence=='':\n",
        "          sentence=\" \"\n",
        "        input_id = tokenizer.encode_plus(sentence,max_length=max_seq_length,pad_to_max_length=True)['input_ids']\n",
        "        input_mask = tokenizer.encode_plus(sentence,max_length=max_seq_length,pad_to_max_length=True)['attention_mask']\n",
        "        segment_id = tokenizer.encode_plus(sentence,max_length=max_seq_length,pad_to_max_length=True)['token_type_ids']\n",
        "        label = label_list[index]\n",
        "        input_ids.append(input_id)\n",
        "        input_masks.append(input_mask)\n",
        "        segment_ids.append(segment_id)\n",
        "        labels.append(label)\n",
        "    return (\n",
        "        np.array(input_ids),\n",
        "        np.array(input_masks),\n",
        "        np.array(segment_ids),\n",
        "        np.array(labels)\n",
        "    )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PjgTX73kNMH",
        "colab_type": "text"
      },
      "source": [
        "Processing textual data using above function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRc2xBf0kGGw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import *\n",
        "tokenizer=RobertaTokenizer.from_pretrained('roberta-base')\n",
        "#tokenizer=AlbertTokenizer.from_pretrained(\"albert-base-v2\")\n",
        "\n",
        "data_train=data_train.reset_index(drop=True)\n",
        "data_val=data_val.reset_index(drop=True)\n",
        "\n",
        "(train_input_ids, train_input_masks, train_segment_ids, train_labels \n",
        ") = convert_examples_to_features(data_train['text'],data_train['class'],max_seq_length,tokenizer)\n",
        "\n",
        "(val_input_ids, val_input_masks, val_segment_ids, val_labels \n",
        ") = convert_examples_to_features(data_val['text'],data_val['class'],max_seq_length,tokenizer)\n",
        "\n",
        "(test_input_ids, test_input_masks, test_segment_ids, test_labels \n",
        ") = convert_examples_to_features(data_test['text'],np.ones(data_test.shape[0]),max_seq_length,tokenizer)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YpsCUNAkOfd",
        "colab_type": "text"
      },
      "source": [
        "Defining F1 metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRBEO-a2j_4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    y_pred = K.round(y_pred)\n",
        "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
        "    # tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
        "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
        "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
        "\n",
        "    p = tp / (tp + fp + K.epsilon())\n",
        "    r = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "    f1 = 2*p*r / (p+r+K.epsilon())\n",
        "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "    return K.mean(f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6cURBzekapJ",
        "colab_type": "text"
      },
      "source": [
        "Keras Callbacks to simplify model saving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NmWfrcukSbo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Saver(tf.keras.callbacks.Callback):\n",
        "  def on_train_begin(self,logs={}):\n",
        "    self.score=0\n",
        "  def on_epoch_end(self,logs={},*args):\n",
        "    #self.model.save_weights('/media/data_dump/Pradyumna/empha/model-{}-{}-{}-{}-L.h5'.format(lr,epochs,dropout,layers))  \n",
        "    predictions=self.model.predict([val_input_ids, val_input_masks, val_segment_ids])\n",
        "    res=f1_score(val_labels,np.argmax(predictions,axis=1),average='macro')\n",
        "    print(\"f1_score=\",res)\n",
        "    if res>self.score:\n",
        "        self.score=res\n",
        "        self.model.save_weights('/content/drive/My Drive/test-2.h5')      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOTsFsgLkj-A",
        "colab_type": "text"
      },
      "source": [
        "Defining model architecture and training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61Vacbbmkeo5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input,Dense,Bidirectional,LSTM\n",
        "\n",
        "\n",
        "# Best hyperparameters\n",
        "lr=1e-5\n",
        "epochs=15\n",
        "layer=0\n",
        "dropout=0\n",
        "\n",
        "\n",
        "\n",
        "token_inputs = tf.keras.layers.Input(shape=(None,), name='word_inputs', dtype=tf.int32)\n",
        "mask_inputs = tf.keras.layers.Input(shape=(None,), name='mask_inputs', dtype=tf.int32)\n",
        "seg_inputs = tf.keras.layers.Input(shape=(None,), name='seg_inputs', dtype=tf.int32)\n",
        "\n",
        "inputs=[token_inputs,mask_inputs,seg_inputs]\n",
        "\n",
        "transformer_outputs= TFRobertaModel.from_pretrained('roberta-base')(inputs)[0][:,0,:]\n",
        "\n",
        "step=transformer_outputs\n",
        "\n",
        "\n",
        "if layer>=3:\n",
        "  step=tf.keras.layers.Dense(512,activation='relu')(step)\n",
        "  if dropout!=0:\n",
        "      step=tf.keras.layers.Dropout(rate=dropout)(step)\n",
        "if layer>=2:\n",
        "  step=tf.keras.layers.Dense(256,activation='relu')(step)\n",
        "  if dropout!=0:\n",
        "      step=tf.keras.layers.Dropout(rate=dropout)(step)\n",
        "if layer>=1:    \n",
        "  step=tf.keras.layers.Dense(64,activation='relu')(step)\n",
        "  if dropout!=0:\n",
        "      step=tf.keras.layers.Dropout(rate=dropout)(step)    \n",
        "\n",
        "\n",
        "pred=tf.keras.layers.Dense(3,activation='softmax')(step)\n",
        "\n",
        "model=tf.keras.Model(inputs=inputs,outputs=pred)\n",
        "\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "      optimizer=tf.keras.optimizers.Adam(lr=lr),\n",
        "      metrics=[f1,'accuracy'])\n",
        "model.summary()\n",
        "\n",
        "#from sklearn.utils.class_weight import compute_class_weight\n",
        "#class_weights = compute_class_weight('balanced', np.unique(data_train.iloc[:,1]), data_train.iloc[:,1])\n",
        "\n",
        "model.fit([train_input_ids,train_input_masks,train_segment_ids],\n",
        "      train_labels,\n",
        "      epochs=epochs,\n",
        "      batch_size=32,\n",
        "      validation_data=([val_input_ids,val_input_masks,val_segment_ids],val_labels),\n",
        "      #class_weight=dict(enumerate(class_weights))  \n",
        "      #callbacks=[\n",
        "          #tf.keras.caltlbacks.LearningRateScheduler(scheduler,verbose=1)\n",
        "          #TensorBoardColabCallback(tbc)\n",
        "          #Saver()\n",
        "      #  ] \n",
        "        )\n",
        "predictions=model.predict([val_input_ids, val_input_masks, val_segment_ids])\n",
        "print(f1_score(val_labels, \n",
        "            np.argmax(predictions,axis=1),average='macro'))\n",
        "print(f1_score(val_labels, \n",
        "            np.argmax(predictions,axis=1),average='micro'))\n",
        "\n",
        "print(\"Done!!\")  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45EHzLJklnP2",
        "colab_type": "text"
      },
      "source": [
        "Final test predictions for submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgtPazBMlXNd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions=model.predict([test_input_ids, test_input_masks, test_segment_ids])\n",
        "prediction=np.argmax(predictions,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9py-594hltEX",
        "colab_type": "text"
      },
      "source": [
        "Making submission file based on the task (A,B,C) being solved "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_76oDwb0ljeY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('answer.txt',\"w\") as f:\n",
        "  for i in range(len(prediction)):\n",
        "    if prediction[i]==2:\n",
        "      f.write(str(-1))\n",
        "    else:\n",
        "      f.write(str(prediction[i]))\n",
        "    f.write(\"_9999_9999\")\n",
        "    f.write(\"\\n\")    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}